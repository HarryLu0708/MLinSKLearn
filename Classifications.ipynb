{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efd282de",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "## Solve for Multiclass Classification Problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5379ed73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ee2f1d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2000, 12), (2000,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = make_classification(n_samples=2000,n_features=12,n_informative=8,n_redundant=4,n_classes=4, random_state=42)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab1c34f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab290b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "\n",
    "ss = StandardScaler()\n",
    "ss.fit(X_train,y_train)\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53c6dcf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[85  8  1  5]\n",
      " [ 3 82  6  4]\n",
      " [12  5 78  7]\n",
      " [ 6  7  7 84]]\n",
      "0.8225\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.86      0.83        99\n",
      "           1       0.80      0.86      0.83        95\n",
      "           2       0.85      0.76      0.80       102\n",
      "           3       0.84      0.81      0.82       104\n",
      "\n",
      "    accuracy                           0.82       400\n",
      "   macro avg       0.82      0.82      0.82       400\n",
      "weighted avg       0.82      0.82      0.82       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "rfc_clf = RandomForestClassifier(random_state=42,n_estimators=500)\n",
    "classifier = rfc_clf.fit(X_train,y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525cec56",
   "metadata": {},
   "source": [
    "### One-vs-Rest for Multiclass Classification\n",
    "\n",
    "In this type of classification, we split the multiclass classification problem into N number of binary classification problems where N is the number of output number. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccf2d750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[66 11 13  9]\n",
      " [ 9 67 10  9]\n",
      " [19 17 53 13]\n",
      " [15 13 17 59]]\n",
      "0.6125\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.67      0.63        99\n",
      "           1       0.62      0.71      0.66        95\n",
      "           2       0.57      0.52      0.54       102\n",
      "           3       0.66      0.57      0.61       104\n",
      "\n",
      "    accuracy                           0.61       400\n",
      "   macro avg       0.61      0.61      0.61       400\n",
      "weighted avg       0.61      0.61      0.61       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_clf = LogisticRegression()\n",
    "clf = OneVsRestClassifier(log_clf)\n",
    "classifier = clf.fit(X_train,y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e610cd9",
   "metadata": {},
   "source": [
    "### One-vs-One for Multiclass Classification\n",
    "\n",
    "In 1-vs-1 classification, a model is trained, which makes a binary classification btw each pair of classes. The class with the highest number of classification is selected on the basis of voting and is labeled as the final predicted output classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1d9d3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[67  7 15 10]\n",
      " [ 5 70 11  9]\n",
      " [18 15 54 15]\n",
      " [11 11 17 65]]\n",
      "0.64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.68      0.67        99\n",
      "           1       0.68      0.74      0.71        95\n",
      "           2       0.56      0.53      0.54       102\n",
      "           3       0.66      0.62      0.64       104\n",
      "\n",
      "    accuracy                           0.64       400\n",
      "   macro avg       0.64      0.64      0.64       400\n",
      "weighted avg       0.64      0.64      0.64       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_clf = LogisticRegression()\n",
    "clf = OneVsOneClassifier(log_clf)\n",
    "classifier = clf.fit(X_train,y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e180fd",
   "metadata": {},
   "source": [
    "## Multilabel Classification Problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74fa9b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2000, 10), (2000, 5))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_multilabel_classification\n",
    "\n",
    "X, y = make_multilabel_classification(n_samples=2000,n_features=10,n_classes=5,n_labels=3, random_state=42)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "383bf858",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "\n",
    "ss = StandardScaler()\n",
    "ss.fit(X_train,y_train)\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57245b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.365\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.73      0.74       186\n",
      "           1       0.86      0.95      0.90       295\n",
      "           2       0.83      0.91      0.87       255\n",
      "           3       0.75      0.91      0.82       243\n",
      "           4       0.74      0.38      0.51       120\n",
      "\n",
      "   micro avg       0.80      0.83      0.82      1099\n",
      "   macro avg       0.79      0.78      0.77      1099\n",
      "weighted avg       0.80      0.83      0.81      1099\n",
      " samples avg       0.83      0.84      0.81      1099\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "rfc_clf = RandomForestClassifier(random_state=42,n_estimators=500)\n",
    "classifier = rfc_clf.fit(X_train,y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc2d3f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.275\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.74      0.76       186\n",
      "           1       0.86      0.89      0.88       295\n",
      "           2       0.81      0.84      0.83       255\n",
      "           3       0.74      0.83      0.78       243\n",
      "           4       0.72      0.39      0.51       120\n",
      "\n",
      "   micro avg       0.80      0.79      0.79      1099\n",
      "   macro avg       0.78      0.74      0.75      1099\n",
      "weighted avg       0.79      0.79      0.78      1099\n",
      " samples avg       0.80      0.81      0.77      1099\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_clf = LogisticRegression()\n",
    "clf = OneVsRestClassifier(log_clf)\n",
    "classifier = clf.fit(X_train,y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190dafd8",
   "metadata": {},
   "source": [
    "## Notes about Metrics\n",
    "- if balance, then use accuracy. \n",
    "- if imbalance, then use F1. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
